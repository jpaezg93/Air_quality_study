{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the neccesary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start by reading the data of US demographics csv file, and save it into the dataframe `us_d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56229.0</td>\n",
       "      <td>62432.0</td>\n",
       "      <td>118661</td>\n",
       "      <td>6634.0</td>\n",
       "      <td>7517.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>IL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41762.0</td>\n",
       "      <td>43270.0</td>\n",
       "      <td>85032</td>\n",
       "      <td>5783.0</td>\n",
       "      <td>3269.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>MO</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hampton</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>35.5</td>\n",
       "      <td>66214.0</td>\n",
       "      <td>70240.0</td>\n",
       "      <td>136454</td>\n",
       "      <td>19638.0</td>\n",
       "      <td>6204.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>VA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>70303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lakewood</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>37.7</td>\n",
       "      <td>76013.0</td>\n",
       "      <td>76576.0</td>\n",
       "      <td>152589</td>\n",
       "      <td>9988.0</td>\n",
       "      <td>14169.0</td>\n",
       "      <td>2.29</td>\n",
       "      <td>CO</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>33630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City       State  Median Age  Male Population  Female Population  \\\n",
       "0    Newark  New Jersey        34.6         138040.0           143873.0   \n",
       "1    Peoria    Illinois        33.1          56229.0            62432.0   \n",
       "2  O'Fallon    Missouri        36.0          41762.0            43270.0   \n",
       "3   Hampton    Virginia        35.5          66214.0            70240.0   \n",
       "4  Lakewood    Colorado        37.7          76013.0            76576.0   \n",
       "\n",
       "   Total Population  Number of Veterans  Foreign-born  Average Household Size  \\\n",
       "0            281913              5829.0       86253.0                    2.73   \n",
       "1            118661              6634.0        7517.0                    2.40   \n",
       "2             85032              5783.0        3269.0                    2.77   \n",
       "3            136454             19638.0        6204.0                    2.48   \n",
       "4            152589              9988.0       14169.0                    2.29   \n",
       "\n",
       "  State Code                               Race  Count  \n",
       "0         NJ                              White  76402  \n",
       "1         IL  American Indian and Alaska Native   1343  \n",
       "2         MO                 Hispanic or Latino   2583  \n",
       "3         VA          Black or African-American  70303  \n",
       "4         CO                 Hispanic or Latino  33630  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_d = pd.read_csv('us-cities-demographics.csv', sep=';')\n",
    "us_d.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the instructions on the website, in this step the API url is used to extract the information about each city Air Quality Index (aqi) and also the concentration measurements for each mayor pollutant in two different lists. In this case we have the list of cities from us extracted from our previous Dataframe `us_d`. The resulting dictionaries contain dictionaries of each city and it's measurments.\n",
    "\n",
    "A list of cities not available in the API is also created under `missing_cities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 400 Could not find city: Augusta-Richmond County consolidated government\n",
      "Error: 400 Could not find city: Urban Honolulu\n",
      "Error: 400 Could not find city: Florence-Graham\n",
      "Error: 400 Could not find city: Louisville/Jefferson County metro government\n"
     ]
    }
   ],
   "source": [
    "api_url = 'https://api.api-ninjas.com/v1/airquality?city='\n",
    "dic = []\n",
    "air_qi = []\n",
    "missing_cities = []\n",
    "for city in us_d['City'].unique():\n",
    "    api_url = f'https://api.api-ninjas.com/v1/airquality?city={city}'\n",
    "    response = requests.get(api_url, headers={'X-Api-Key': 'gBiipiwSiMtD3TpF+QIlYg==OAPqGhEzwXmgGZwS'})\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        data = response.json()\n",
    "        dic.append({'city':city})\n",
    "        air_qi.append({'city':city})\n",
    "        for key, value in data.items():\n",
    "            if key != 'overall_aqi':\n",
    "                dic.append({key:value.get('concentration')})\n",
    "                air_qi.append({key:value.get('aqi')})\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, f'Could not find city: {city}')\n",
    "        missing_cities.append(city)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the list `dic` that contains all of the cities and it's measurments of major pollutants to create a dataframe with the name `us_aq_1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n"
     ]
    }
   ],
   "source": [
    "print(len(us_d['City'].unique()))\n",
    "rows = []\n",
    "for i in range(0, len(dic), 7):\n",
    "    row = []\n",
    "    for j in range(7):\n",
    "        row.append(list(dic[i+j].values())[0])\n",
    "    rows.append(row)\n",
    "# Define the column names\n",
    "columns = ['city', 'CO', 'NO2', 'O3', 'SO2', 'PM2.5', 'PM10']\n",
    "# Create the dataframe from the rows and columns\n",
    "us_aq_1 = pd.DataFrame(rows, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the list `air_qi` that contains all of the cities and it's air quality indices of major pollutants to create a dataframe with the name `us_aqi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>CO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hampton</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lakewood</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city  CO  NO2  O3  SO2  PM2.5  PM10\n",
       "0    Newark   4   38  27    5     51    18\n",
       "1    Peoria   4   26   4    0     18     6\n",
       "2  O'Fallon   4   29  10    0     28    11\n",
       "3   Hampton   3    7  51    4     29     9\n",
       "4  Lakewood   3   18  37    0     10     5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for i in range(0, len(air_qi), 7):\n",
    "    row = []\n",
    "    for j in range(7):\n",
    "        row.append(list(air_qi[i+j].values())[0])\n",
    "    rows.append(row)\n",
    "# Define the column names\n",
    "columns = ['city', 'CO', 'NO2', 'O3', 'SO2', 'PM2.5', 'PM10']\n",
    "# Create the dataframe from the rows and columns\n",
    "us_aqi = pd.DataFrame(rows, columns=columns)\n",
    "us_aqi.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step ensures the cleaning of the data by removing the unnecesary columns and duplicated rows in the `us_d` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_d.drop(columns=['Race', 'Count', 'Number of Veterans'], inplace= True, axis=1)\n",
    "us_d.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a SQLite database `air_quality_study.db` that has two tables. One table created from the `us_aqi` dataframe and the second table from `us_d` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_aqi.rename(columns={'PM2.5':'PM2_5'},inplace=True)\n",
    "\n",
    "conn = sqlite3.connect('air_quality_study.db')\n",
    "cur = conn.cursor()\n",
    "us_aqi.to_sql('air_quality', conn, if_exists='replace', index=False)\n",
    "us_d.to_sql('us_demographics', conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we tried to check if the most populated cities also have the worst air quality.\n",
    "To answer the question we first made a query into our `air_quality_study.db` to see which are the 10 most populated cities in the US usin the `us_demographics` table.\n",
    "We then checked for the top 10 cities that had the worst air quality indeces for each major polutant and it's avarage. We saved the results of our queries in the list `results` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('air_quality_study.db')\n",
    "cur = conn.cursor()\n",
    "query_1 = 'SELECT \"city\" FROM \"us_demographics\" ORDER BY \"total population\" DESC LIMIT 10'\n",
    "query_summary = 'SELECT \"city\" FROM (SELECT * FROM \"air_quality\") '\n",
    "query_2 = 'SELECT \"city\" FROM \"air_quality\" ORDER BY \"CO\" LIMIT 10'\n",
    "query_3 = 'SELECT \"city\" FROM \"air_quality\" ORDER BY \"NO2\" LIMIT 10'\n",
    "query_4 = 'SELECT \"city\" FROM \"air_quality\" ORDER BY \"O3\" LIMIT 10'\n",
    "query_5 = 'SELECT \"city\" FROM \"air_quality\" ORDER BY \"SO2\" LIMIT 10'\n",
    "query_6 = 'SELECT \"city\" FROM \"air_quality\" ORDER BY \"PM2_5\" LIMIT 10'\n",
    "query_7 = 'SELECT \"city\" FROM \"air_quality\" ORDER BY \"PM10\" LIMIT 10'\n",
    "query_8 = 'SELECT \"city\" FROM (SELECT \"city\", (\"CO\"+\"NO2\"+\"O3\"+\"SO2\"+\"PM2_5\"+\"PM10\")/6 as \"avarage\" FROM \"air_quality\" ORDER BY \"avarage\" LIMIT 10)'\n",
    "most_populated_cities = cur.execute(query_1).fetchall()\n",
    "CO_most_contaminated = cur.execute(query_2).fetchall()\n",
    "NO3_most_contaminated = cur.execute(query_3).fetchall()\n",
    "O3_most_contaminated = cur.execute(query_4).fetchall()\n",
    "SO2_most_contaminated = cur.execute(query_5).fetchall()\n",
    "PM2_5_most_contaminated = cur.execute(query_6).fetchall()\n",
    "PM10_most_contaminated = cur.execute(query_7).fetchall()\n",
    "most_contaminated_avg = cur.execute(query_8).fetchall()\n",
    "conn.close()\n",
    "l1=[str(city[0]) for city in most_populated_cities]    \n",
    "l1 = {'most_populated_cities':l1}\n",
    "l2=[str(city[0]) for city in CO_most_contaminated]    \n",
    "l2 = {'CO_most_contaminated':l2}\n",
    "l3=[str(city[0]) for city in NO3_most_contaminated]    \n",
    "l3 = {'NO3_most_contaminated':l3}\n",
    "l4=[str(city[0]) for city in O3_most_contaminated]    \n",
    "l4 = {'O3_most_contaminated':l4}\n",
    "l5=[str(city[0]) for city in SO2_most_contaminated]    \n",
    "l5 = {'SO2_most_contaminated':l5}\n",
    "l6=[str(city[0]) for city in PM2_5_most_contaminated]    \n",
    "l6 = {'PM2_5_most_contaminated':l6}\n",
    "l7=[str(city[0]) for city in PM10_most_contaminated]    \n",
    "l7 = {'PM10_most_contaminated':l7}\n",
    "l8=[str(city[0]) for city in most_contaminated_avg]    \n",
    "l8 = {'most_contaminated_avg':l8}\n",
    "results = [l1,l2,l3,l4,l5,l6,l7,l8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last we created a Dataframe that contains all the results of our queries, which has the names of the cities with the most populated cities and the cities with the worst air quality indices for each major pollutant and the avarage overall. We ordered each column in alphabetic order independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most_populated_cities</th>\n",
       "      <th>CO_most_contaminated</th>\n",
       "      <th>NO3_most_contaminated</th>\n",
       "      <th>O3_most_contaminated</th>\n",
       "      <th>SO2_most_contaminated</th>\n",
       "      <th>PM2_5_most_contaminated</th>\n",
       "      <th>PM10_most_contaminated</th>\n",
       "      <th>most_contaminated_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Billings</td>\n",
       "      <td>Bayamón</td>\n",
       "      <td>Anaheim</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>Bay</td>\n",
       "      <td>Bay</td>\n",
       "      <td>Bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>Caguas</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Dothan</td>\n",
       "      <td>Bayonne</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>Bayamón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston</td>\n",
       "      <td>Bryan</td>\n",
       "      <td>Carmichael</td>\n",
       "      <td>Brentwood</td>\n",
       "      <td>Flint</td>\n",
       "      <td>Brandon</td>\n",
       "      <td>Brandon</td>\n",
       "      <td>Caguas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Carmichael</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Costa Mesa</td>\n",
       "      <td>Fort Smith</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>Guaynabo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>Dothan</td>\n",
       "      <td>German</td>\n",
       "      <td>Fullerton</td>\n",
       "      <td>Lakewood</td>\n",
       "      <td>Cheektowaga</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Mayagüez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Largo</td>\n",
       "      <td>Mayagüez</td>\n",
       "      <td>Jurupa Valley</td>\n",
       "      <td>Madison</td>\n",
       "      <td>Erie</td>\n",
       "      <td>Cheektowaga</td>\n",
       "      <td>Ponce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>New Britain</td>\n",
       "      <td>Kirkland</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>Erie</td>\n",
       "      <td>Rockford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>San Clemente</td>\n",
       "      <td>Saint George</td>\n",
       "      <td>Moreno Valley</td>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>Warwick</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>San Clemente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>Shreveport</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>Newport Beach</td>\n",
       "      <td>Peoria</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Warwick</td>\n",
       "      <td>San Ramon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>Toledo</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Santa Ana</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>Yakima</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Toledo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  most_populated_cities CO_most_contaminated NO3_most_contaminated  \\\n",
       "0               Chicago             Billings               Bayamón   \n",
       "1                Dallas              Boulder                Caguas   \n",
       "2               Houston                Bryan            Carmichael   \n",
       "3           Los Angeles           Carmichael              Carolina   \n",
       "4              New York               Dothan                German   \n",
       "5          Philadelphia                Largo              Mayagüez   \n",
       "6               Phoenix                 Mesa           New Britain   \n",
       "7           San Antonio         San Clemente          Saint George   \n",
       "8             San Diego           Shreveport              San Juan   \n",
       "9              San Jose               Toledo                Weston   \n",
       "\n",
       "  O3_most_contaminated SO2_most_contaminated PM2_5_most_contaminated  \\\n",
       "0              Anaheim               Boulder                     Bay   \n",
       "1              Atlanta                Dothan                 Bayonne   \n",
       "2            Brentwood                 Flint                 Brandon   \n",
       "3           Costa Mesa            Fort Smith                 Buffalo   \n",
       "4            Fullerton              Lakewood             Cheektowaga   \n",
       "5        Jurupa Valley               Madison                    Erie   \n",
       "6             Kirkland                  Mesa               Rochester   \n",
       "7        Moreno Valley              O'Fallon                 Warwick   \n",
       "8        Newport Beach                Peoria                  Weston   \n",
       "9            Santa Ana           Springfield                  Yakima   \n",
       "\n",
       "  PM10_most_contaminated most_contaminated_avg  \n",
       "0                    Bay                   Bay  \n",
       "1                Boulder               Bayamón  \n",
       "2                Brandon                Caguas  \n",
       "3                Buffalo              Guaynabo  \n",
       "4              Cambridge              Mayagüez  \n",
       "5            Cheektowaga                 Ponce  \n",
       "6                   Erie              Rockford  \n",
       "7              Rochester          San Clemente  \n",
       "8                Warwick             San Ramon  \n",
       "9                 Weston                Toledo  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty dataframe with 10 rows\n",
    "df = pd.DataFrame(index=range(10))\n",
    "# Loop through the list and add each dictionary as a column to the dataframe\n",
    "for d in results:\n",
    "    # Get the key and value of the dictionary\n",
    "    key = list(d.keys())[0]\n",
    "    value = list(d.values())[0]\n",
    "    # Add the column to the dataframe with the key as the name and the value as the data\n",
    "    df[key] = value\n",
    "# Looping through the columns and sort them by alphabetic order\n",
    "for col in df.columns:\n",
    "    # Sort the column and reset the index\n",
    "    df[col] = df[col].sort_values().reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then our last step is to check if the most populated cities had the worst air quality indices (aqi) by checking if this list of cities is within the list of the cities with the worst aqi for each major pollutant and it's avarage.\n",
    "Even though we didn't find the top ten most populated cities didn't have the worst air quality, we recomend further analisys to check the relationship of population size with air quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of the most populated cities that are within the top 10 most contaminated cities\n",
      "given different measurments (CO, NO2, O3, SO2, PM2_5, PM10, Avarage): 0\n"
     ]
    }
   ],
   "source": [
    "city_presence = df['most_populated_cities'].isin(df.drop('most_populated_cities', axis=1).values.ravel())\n",
    "city_count = city_presence.sum()\n",
    "print(f'number of the most populated cities that are within the top 10 most contaminated cities\\ngiven different measurments (CO, NO2, O3, SO2, PM2_5, PM10, Avarage): {city_count}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
